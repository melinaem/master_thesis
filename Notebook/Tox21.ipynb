{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# USING DEEPCHEM"
      ],
      "metadata": {
        "id": "y3ZW3FJPt18P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import deepchem as dc \n",
        "from deepchem.models import GraphConvModel\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import numpy as np \n",
        "import tempfile\n",
        "\n"
      ],
      "metadata": {
        "id": "Sd0A_sbAr-z3"
      },
      "execution_count": 211,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tox21_tasks, tox21_datasets, transformers = dc.molnet.load_tox21()\n",
        "train_dataset, valid_dataset, test_dataset = tox21_datasets"
      ],
      "metadata": {
        "id": "DdgWqn-fgcoh"
      },
      "execution_count": 212,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def model_builder_svc(model_dir):\n",
        "  sklearn_model = SVC(C=1.0, class_weight=\"balanced\", probability=True)\n",
        "  return dc.models.SklearnModel(sklearn_model, model_dir)\n",
        "\n",
        "\n",
        "model_dir = tempfile.mkdtemp()\n",
        "model_svc = dc.models.SingletaskToMultitask(tox21_tasks, model_builder_svc, model_dir)\n",
        "\n",
        "# Fit trained model\n",
        "model_svc.fit(train_dataset)"
      ],
      "metadata": {
        "id": "-a9_vRNqLTI6"
      },
      "execution_count": 213,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def model_builder_rf(model_dir):\n",
        "  sklearn_model = RandomForestClassifier(class_weight=\"balanced\")\n",
        "  return dc.models.SklearnModel(sklearn_model, model_dir)\n",
        "\n",
        "\n",
        "model_dir = tempfile.mkdtemp()\n",
        "model_rf = dc.models.SingletaskToMultitask(tox21_tasks, model_builder_rf, model_dir)\n",
        "\n",
        "# Fit trained model\n",
        "model_rf.fit(train_dataset)"
      ],
      "metadata": {
        "id": "SNKdOQkFL2Wg"
      },
      "execution_count": 218,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import deepchem as dc\n",
        "import numpy as np\n",
        "from deepchem.models import GraphConvModel\n",
        "\n",
        "np.random.seed(0)\n",
        "\n",
        "# Load Tox21 dataset\n",
        "tox21_tasks_gcn, tox21_datasets_gcn, transformers_gcn = dc.molnet.load_tox21(featurizer='GraphConv')\n",
        "train_dataset_gcn, valid_dataset_gcn, test_dataset_gcn = tox21_datasets_gcn\n",
        "\n",
        "#try with differnet batch_size and npepoch\n",
        "model_gcn = GraphConvModel(\n",
        "    len(tox21_tasks_gcn), batch_size=64, mode='classification', random_seed=0)\n",
        "# Set nb_epoch=10 for better results.\n",
        "model_gcn.fit(train_dataset_gcn, nb_epoch=2000,  deterministic=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KD7oJb_xt0WZ",
        "outputId": "52a132ba-d664-4a58-d9ca-cc0dcc644636"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_14:0\", shape=(256,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_13:0\", shape=(256, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_17:0\", shape=(672,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_16:0\", shape=(672, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_20:0\", shape=(240,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_19:0\", shape=(240, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_23:0\", shape=(88,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_22:0\", shape=(88, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_11:0\", shape=(256,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_10:0\", shape=(256, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_13:0\", shape=(672,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_12:0\", shape=(672, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Cast_1:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_15:0\", shape=(240,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_14:0\", shape=(240, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Cast_2:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_17:0\", shape=(88,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_16:0\", shape=(88, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Cast_3:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_19:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_18:0\", shape=(0, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_21:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_20:0\", shape=(0, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_23:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_22:0\", shape=(0, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_25:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_24:0\", shape=(0, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_27:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_26:0\", shape=(0, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Cast_8:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_29:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_28:0\", shape=(0, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Cast_9:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_14:0\", shape=(256,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_13:0\", shape=(256, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_17:0\", shape=(672,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_16:0\", shape=(672, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_20:0\", shape=(240,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_19:0\", shape=(240, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_23:0\", shape=(88,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_22:0\", shape=(88, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_14:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_13:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_17:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_16:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_20:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_19:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_23:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_22:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_11:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_10:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_13:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_12:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Cast_1:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_15:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_14:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Cast_2:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_17:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_16:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Cast_3:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_14:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_13:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_17:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_16:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_20:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_19:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_23:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_22:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_26:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_25:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Cast_8:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_29:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_28:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Cast_9:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_19:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_18:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_26:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_25:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Cast_8:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_29:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_28:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Cast_9:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_32:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_31:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Cast_10:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_35:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_34:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Cast_11:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_21:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_20:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_32:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_31:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Cast_10:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_35:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_34:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Cast_11:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0022217954695224764"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "metric_rocauc = dc.metrics.Metric(dc.metrics.roc_auc_score, np.mean)\n",
        "metric_recall = dc.metrics.Metric(dc.metrics.recall_score)\n",
        "metric_f1 = dc.metrics.Metric(dc.metrics.f1_score)\n",
        "metric_accuracy = dc.metrics.Metric(dc.metrics.accuracy_score)\n"
      ],
      "metadata": {
        "id": "_fJ-fAWKJrU0"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Evaluating Support Vector Classifier\")\n",
        "train_scores_svc = model_svc.evaluate(train_dataset, [metric_rocauc, metric_recall, metric_f1, metric_accuracy], transformers)\n",
        "print(\"Training ROC-AUC Scores: %f\" % (train_scores_svc[\"mean-roc_auc_score\"]))\n",
        "print(\"Training Recall Scores: %f\" % (train_scores_svc[\"recall_score\"]))\n",
        "print(\"Training F1 Scores: %f\" % (train_scores_svc[\"f1_score\"]))\n",
        "print(\"Training Accuracy Scores: %f\" % (train_scores_svc[\"accuracy_score\"]))\n",
        "\n",
        "valid_scores_svc = model_svc.evaluate(valid_dataset, [metric_rocauc, metric_recall, metric_f1, metric_accuracy], transformers)\n",
        "print(\"Validation ROC-AUC Scores: %f\" % (valid_scores_svc[\"mean-roc_auc_score\"]))\n",
        "print(\"Validation Recall Scores: %f\" % (valid_scores_svc[\"recall_score\"]))\n",
        "print(\"Validation F1 Scores: %f\" % (valid_scores_svc[\"f1_score\"]))\n",
        "print(\"Validation Accuracy Scores: %f\" % (valid_scores_svc[\"accuracy_score\"]))\n",
        "\n",
        "\n",
        "test_scores_svc = model_svc.evaluate(test_dataset, [metric_rocauc, metric_recall, metric_f1, metric_accuracy], transformers)\n",
        "print(\"Test ROC-AUC Scores: %f\" % (test_scores_svc[\"mean-roc_auc_score\"]))\n",
        "print(\"Test Recall Scores: %f\" % (test_scores_svc[\"recall_score\"]))\n",
        "print(\"Test F1 Scores: %f\" % (test_scores_svc[\"f1_score\"]))\n",
        "print(\"Test Accuracy Scores: %f\" % (test_scores_svc[\"accuracy_score\"]))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tu0fPMDvo_SF",
        "outputId": "19234c90-001e-4e14-918c-dc8122117fc0"
      },
      "execution_count": 217,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating Support Vector Classifier\n",
            "Training ROC-AUC Scores: 0.996217\n",
            "Training Recall Scores: 0.923238\n",
            "Training F1 Scores: 0.849554\n",
            "Training Accuracy Scores: 0.980736\n",
            "Validation ROC-AUC Scores: 0.741793\n",
            "Validation Recall Scores: 0.050222\n",
            "Validation F1 Scores: 0.084521\n",
            "Validation Accuracy Scores: 0.925819\n",
            "Test ROC-AUC Scores: 0.707326\n",
            "Test Recall Scores: 0.049410\n",
            "Test F1 Scores: 0.078736\n",
            "Test Accuracy Scores: 0.928997\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Evaluating Random Forest\")\n",
        "train_scores_rf = model_rf.evaluate(train_dataset, [metric_rocauc, metric_recall, metric_f1, metric_accuracy], transformers)\n",
        "print(\"Training ROC-AUC Scores: %f\" % (train_scores_rf[\"mean-roc_auc_score\"]))\n",
        "print(\"Training Recall Scores: %f\" % (train_scores_rf[\"recall_score\"]))\n",
        "print(\"Training F1 Scores: %f\" % (train_scores_rf[\"f1_score\"]))\n",
        "print(\"Test Accuracy Scores: %f\" % (train_scores_rf[\"accuracy_score\"]))\n",
        "\n",
        "\n",
        "valid_scores_rf = model_rf.evaluate(valid_dataset, [metric_rocauc, metric_recall, metric_f1, metric_accuracy], transformers)\n",
        "print(\"Validation ROC-AUC Scores: %f\" % (valid_scores_rf[\"mean-roc_auc_score\"]))\n",
        "print(\"Validation Recall Scores: %f\" % (valid_scores_rf[\"recall_score\"]))\n",
        "print(\"Validation F1 Scores: %f\" % (valid_scores_rf[\"f1_score\"]))\n",
        "print(\"Test Accuracy Scores: %f\" % (valid_scores_rf[\"accuracy_score\"]))\n",
        "\n",
        "\n",
        "test_scores_rf = model_rf.evaluate(test_dataset, [metric_rocauc, metric_recall, metric_f1, metric_accuracy], transformers)\n",
        "print(\"Test ROC-AUC Scores: %f\" % (test_scores_rf[\"mean-roc_auc_score\"]))\n",
        "print(\"Test Recall Scores: %f\" % (test_scores_rf[\"recall_score\"]))\n",
        "print(\"Test F1 Scores: %f\" % (test_scores_rf[\"f1_score\"]))\n",
        "print(\"Test Accuracy Scores: %f\" % (test_scores_rf[\"accuracy_score\"]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BpKnDi0c3aWZ",
        "outputId": "5d93e3c2-9ea2-4126-c4ec-f9cf325a3431"
      },
      "execution_count": 219,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating Random Forest\n",
            "Training ROC-AUC Scores: 0.997331\n",
            "Training Recall Scores: 0.998240\n",
            "Training F1 Scores: 0.943986\n",
            "Test Accuracy Scores: 0.992271\n",
            "Validation ROC-AUC Scores: 0.667072\n",
            "Validation Recall Scores: 0.086695\n",
            "Validation F1 Scores: 0.140050\n",
            "Test Accuracy Scores: 0.928587\n",
            "Test ROC-AUC Scores: 0.649313\n",
            "Test Recall Scores: 0.050343\n",
            "Test F1 Scores: 0.083974\n",
            "Test Accuracy Scores: 0.929315\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Evaluating GCN model\")\n",
        "train_scores_gcn = model_gcn.evaluate(train_dataset_gcn, [metric_rocauc, metric_recall, metric_f1, metric_accuracy], transformers_gcn)\n",
        "print(\"Training ROC-AUC Scores: %f\" % (train_scores_gcn[\"mean-roc_auc_score\"]))\n",
        "print(\"Training Recall Scores: %f\" % (train_scores_gcn[\"recall_score\"]))\n",
        "print(\"Training F1 Scores: %f\" % (train_scores_gcn[\"f1_score\"]))\n",
        "print(\"Training Accuracy Scores: %f\" % (train_scores_gcn[\"accuracy_score\"]))\n",
        "\n",
        "\n",
        "\n",
        "valid_scores_gcn = model_gcn.evaluate(valid_dataset_gcn, [metric_rocauc, metric_recall, metric_f1, metric_accuracy], transformers_gcn)\n",
        "print(\"Validation ROC-AUC Scores: %f\" % (valid_scores_gcn[\"mean-roc_auc_score\"]))\n",
        "print(\"Validation Recall Scores: %f\" % (valid_scores_gcn[\"recall_score\"]))\n",
        "print(\"Validation F1 Scores: %f\" % (valid_scores_gcn[\"f1_score\"]))\n",
        "print(\"Validation Accuracy Scores: %f\" % (valid_scores_gcn[\"accuracy_score\"]))\n",
        "\n",
        "\n",
        "test_scores_gcn = model_gcn.evaluate(test_dataset_gcn, [metric_rocauc, metric_recall, metric_f1, metric_accuracy], transformers_gcn)\n",
        "print(\"Test ROC-AUC Scores: %f\" % (test_scores_gcn[\"mean-roc_auc_score\"]))\n",
        "print(\"Test Recall Scores: %f\" % (test_scores_gcn[\"recall_score\"]))\n",
        "print(\"Test F1 Scores: %f\" % (test_scores_gcn[\"f1_score\"]))\n",
        "print(\"Test Accuracy Scores: %f\" % (test_scores_gcn[\"accuracy_score\"]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "thEN58nz4-21",
        "outputId": "41ff44a8-7cdc-4511-f1a7-96cdf61df8fb"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating GCN model\n",
            "Training ROC-AUC Scores: 0.945238\n",
            "Training Recall Scores: 0.681203\n",
            "Training F1 Scores: 0.613994\n",
            "Training Accuracy Scores: 0.948223\n",
            "Validation ROC-AUC Scores: 0.715671\n",
            "Validation Recall Scores: 0.331218\n",
            "Validation F1 Scores: 0.284748\n",
            "Validation Accuracy Scores: 0.877501\n",
            "Test ROC-AUC Scores: 0.649116\n",
            "Test Recall Scores: 0.277435\n",
            "Test F1 Scores: 0.217470\n",
            "Test Accuracy Scores: 0.869685\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Bxrs0_RDzOT"
      },
      "source": [
        "## Using PyTorch Gemoetric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "GRidEwlC4oy4"
      },
      "outputs": [],
      "source": [
        "import rdkit\n",
        "from torch_geometric.datasets import MoleculeNet\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5dmHuk8w4-Pf",
        "outputId": "a39d5fc3-695f-4c59-e853-685254aeeddc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://deepchemdata.s3-us-west-1.amazonaws.com/datasets/tox21.csv.gz\n",
            "Extracting ./tox21/raw/tox21.csv.gz\n",
            "Processing...\n",
            "Done!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Tox21(7831)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "data = MoleculeNet(root=\".\", name=\"Tox21\")\n",
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RYEIOzt6C3-E",
        "outputId": "eb16fff2-0fc9-4ae6-b562-6aba25215fd0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset type:  <class 'torch_geometric.datasets.molecule_net.MoleculeNet'>\n",
            "Dataset features:  9\n",
            "Dataset target:  12\n",
            "Dataset length:  <bound method InMemoryDataset.len of Tox21(7831)>\n",
            "Dataset sample:  Data(x=[16, 9], edge_index=[2, 34], edge_attr=[34, 3], smiles='CCOc1ccc2nc(S(N)(=O)=O)sc2c1', y=[1, 12])\n",
            "Sample  nodes:  16\n",
            "Sample  edges:  34\n"
          ]
        }
      ],
      "source": [
        "# Investigating the dataset\n",
        "print(\"Dataset type: \", type(data))\n",
        "print(\"Dataset features: \", data.num_features)\n",
        "print(\"Dataset target: \", data.num_classes)\n",
        "print(\"Dataset length: \", data.len)\n",
        "print(\"Dataset sample: \", data[0])\n",
        "print(\"Sample  nodes: \", data[0].num_nodes)\n",
        "print(\"Sample  edges: \", data[0].num_edges)\n",
        "\n",
        "# edge_index = graph connections\n",
        "# smiles = molecule with its atoms\n",
        "# x = node features (16 nodes have each 9 features)\n",
        "# y = labels (dimension)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iy601ibvDECI",
        "outputId": "30f01bee-b063-4531-9ec0-012115023f0e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 6,  0,  4,  5,  3,  0,  4,  0,  0],\n",
              "        [ 6,  0,  4,  5,  2,  0,  4,  0,  0],\n",
              "        [ 8,  0,  2,  5,  0,  0,  3,  0,  0],\n",
              "        [ 6,  0,  3,  5,  0,  0,  3,  1,  1],\n",
              "        [ 6,  0,  3,  5,  1,  0,  3,  1,  1],\n",
              "        [ 6,  0,  3,  5,  1,  0,  3,  1,  1],\n",
              "        [ 6,  0,  3,  5,  0,  0,  3,  1,  1],\n",
              "        [ 7,  0,  2,  5,  0,  0,  3,  1,  1],\n",
              "        [ 6,  0,  3,  5,  0,  0,  3,  1,  1],\n",
              "        [16,  0,  4,  5,  0,  0,  4,  0,  0],\n",
              "        [ 7,  0,  3,  5,  2,  0,  4,  0,  0],\n",
              "        [ 8,  0,  1,  5,  0,  0,  3,  0,  0],\n",
              "        [ 8,  0,  1,  5,  0,  0,  3,  0,  0],\n",
              "        [16,  0,  2,  5,  0,  0,  3,  1,  1],\n",
              "        [ 6,  0,  3,  5,  0,  0,  3,  1,  1],\n",
              "        [ 6,  0,  3,  5,  1,  0,  3,  1,  1]])"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data[0].x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aKpNiL15DP-3",
        "outputId": "29141032-c3d3-4d8a-b31e-96bdf20f3016"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 0,  1],\n",
              "        [ 1,  0],\n",
              "        [ 1,  2],\n",
              "        [ 2,  1],\n",
              "        [ 2,  3],\n",
              "        [ 3,  2],\n",
              "        [ 3,  4],\n",
              "        [ 3, 15],\n",
              "        [ 4,  3],\n",
              "        [ 4,  5],\n",
              "        [ 5,  4],\n",
              "        [ 5,  6],\n",
              "        [ 6,  5],\n",
              "        [ 6,  7],\n",
              "        [ 6, 14],\n",
              "        [ 7,  6],\n",
              "        [ 7,  8],\n",
              "        [ 8,  7],\n",
              "        [ 8,  9],\n",
              "        [ 8, 13],\n",
              "        [ 9,  8],\n",
              "        [ 9, 10],\n",
              "        [ 9, 11],\n",
              "        [ 9, 12],\n",
              "        [10,  9],\n",
              "        [11,  9],\n",
              "        [12,  9],\n",
              "        [13,  8],\n",
              "        [13, 14],\n",
              "        [14,  6],\n",
              "        [14, 13],\n",
              "        [14, 15],\n",
              "        [15,  3],\n",
              "        [15, 14]])"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data[0].edge_index.t() #shows the connections between two nodes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BgiaIF0ODi8B",
        "outputId": "fbba9d55-ac9f-4ba2-bd5c-0706e1f16e0b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0., 0., 1., nan, nan, 0., 0., 1., 0., 0., 0., 0.]])"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data[0].y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "p8XyhyHODope",
        "outputId": "2fd02af1-c6b8-437f-d282-2413d37c0497"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'CCOc1ccc2nc(S(N)(=O)=O)sc2c1'"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data[0][\"smiles\"]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ouM5OIx9g7m",
        "outputId": "999d93e7-37c1-4d9c-b49e-e1789ae63e05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Data(x=[16, 9], edge_index=[2, 34], edge_attr=[34, 3], smiles='CCOc1ccc2nc(S(N)(=O)=O)sc2c1', y=[1, 12])"
            ]
          },
          "metadata": {},
          "execution_count": 142
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Srj8xzS7DuEl"
      },
      "source": [
        "### Converting to RDKit molecules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jNtiCDqgDoXt"
      },
      "outputs": [],
      "source": [
        "from rdkit import Chem\n",
        "from rdkit.Chem.Draw import IPythonConsole"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        },
        "id": "OonbeJ6QDtiy",
        "outputId": "8085c05a-aedb-407b-ea65-d6af42795662"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<rdkit.Chem.rdchem.Mol at 0x7f9ee747d350>"
            ],
            "image/png": "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\n"
          },
          "metadata": {},
          "execution_count": 144
        }
      ],
      "source": [
        "molecule = Chem.MolFromSmiles(data[0][\"smiles\"])\n",
        "molecule"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V-v33dndD_WS",
        "outputId": "01812de0-a079-47f7-bb77-f4248493d9cc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "rdkit.Chem.rdchem.Mol"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(molecule)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HvkpFxCgJERn"
      },
      "source": [
        "### Implementation: GCN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "_M9252ctv8TM"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch_geometric.nn import GCNConv\n",
        "from torch.nn import Linear\n",
        "import torch.nn.functional as F \n",
        "from torch_geometric.nn import global_mean_pool as gap, global_max_pool as gmp\n",
        "\n",
        "\n",
        "embedding_size = 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "sF_tY_NFv-56"
      },
      "outputs": [],
      "source": [
        "class GCN(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        # Init parent\n",
        "        super(GCN, self).__init__()\n",
        "        torch.manual_seed(42)\n",
        "\n",
        "        # GCN layers\n",
        "        self.initial_conv = GCNConv(data.num_features, embedding_size)\n",
        "        self.conv1 = GCNConv(embedding_size, embedding_size)\n",
        "        self.conv2 = GCNConv(embedding_size, embedding_size)\n",
        "        self.conv3 = GCNConv(embedding_size, embedding_size)\n",
        "\n",
        "        # Output layer\n",
        "        self.out = Linear(embedding_size*2, 12)\n",
        "\n",
        "    def forward(self, x, edge_index, batch_index):\n",
        "        # First Conv layer\n",
        "        hidden = self.initial_conv(x, edge_index)\n",
        "        hidden = F.tanh(hidden)\n",
        "        #hidden = F.leaky_relu(hidden)\n",
        "\n",
        "        # Other Conv layers\n",
        "        hidden = self.conv1(hidden, edge_index)\n",
        "        hidden = F.tanh(hidden)\n",
        "        #hidden = F.leaky_relu(hidden)\n",
        "\n",
        "        hidden = self.conv2(hidden, edge_index)\n",
        "        hidden = F.tanh(hidden)\n",
        "        #hidden = F.leaky_relu(hidden)\n",
        "\n",
        "        hidden = self.conv3(hidden, edge_index)\n",
        "        hidden = F.tanh(hidden)\n",
        "        #hidden = F.leaky_relu(hidden)\n",
        "          \n",
        "        # Global Pooling (stack different aggregations)\n",
        "        hidden = torch.cat([gmp(hidden, batch_index), \n",
        "                            gap(hidden, batch_index)], dim=1)\n",
        "\n",
        "        # Apply a final (linear) classifier.\n",
        "        out = self.out(hidden)\n",
        "        return out, hidden"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RwibiOkywF4K",
        "outputId": "5430df3e-2228-49a9-d46a-6160a4d7eef5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GCN(\n",
            "  (initial_conv): GCNConv(9, 64)\n",
            "  (conv1): GCNConv(64, 64)\n",
            "  (conv2): GCNConv(64, 64)\n",
            "  (conv3): GCNConv(64, 64)\n",
            "  (out): Linear(in_features=128, out_features=12, bias=True)\n",
            ")\n",
            "Number of parameters:  14668\n"
          ]
        }
      ],
      "source": [
        "model = GCN()\n",
        "print(model)\n",
        "print(\"Number of parameters: \", sum(p.numel() for p in model.parameters()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D0-JO32aKuZF"
      },
      "source": [
        "### Training the GCN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "N0r-nHURc6eN"
      },
      "outputs": [],
      "source": [
        "from torch_geometric.data import DataLoader\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "apCKeMUCjqTR"
      },
      "outputs": [],
      "source": [
        "# Root mean squared error\n",
        "\n",
        "loss_fn = torch.nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.0001) \n",
        "\n",
        "# Use GPU for training\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "#model = model.to(device)\n",
        "\n",
        "# Wrap data in a data loader\n",
        "data_size = len(data)\n",
        "NUM_GRAPHS_PER_BATCH = 64\n",
        "loader = DataLoader(data[:int(data_size * 0.8)], \n",
        "                    batch_size=NUM_GRAPHS_PER_BATCH, shuffle=True, drop_last=True)\n",
        "test_loader = DataLoader(data[int(data_size * 0.8):], \n",
        "                         batch_size=NUM_GRAPHS_PER_BATCH, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "GrsjL1LH0BAg"
      },
      "outputs": [],
      "source": [
        "from torch import autograd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 220,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KVOECzi6K1vH",
        "outputId": "c2839ec9-99a0-4d4e-e396-02f2441053b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training...\n",
            "Epoch 0 | Train Loss 0.09511402994394302\n",
            "Epoch 100 | Train Loss 0.05370516702532768\n",
            "Epoch 200 | Train Loss 0.04577479884028435\n",
            "Epoch 300 | Train Loss 0.04460771381855011\n",
            "Epoch 400 | Train Loss 0.05260516703128815\n",
            "Epoch 500 | Train Loss 0.0673525258898735\n",
            "Epoch 600 | Train Loss 0.06452664732933044\n",
            "Epoch 700 | Train Loss 0.05067691579461098\n",
            "Epoch 800 | Train Loss 0.05008960887789726\n",
            "Epoch 900 | Train Loss 0.05497562512755394\n",
            "Epoch 1000 | Train Loss 0.05479394271969795\n",
            "Epoch 1100 | Train Loss 0.05499710142612457\n",
            "Epoch 1200 | Train Loss 0.08467570692300797\n",
            "Epoch 1300 | Train Loss 0.04115467891097069\n",
            "Epoch 1400 | Train Loss 0.07038872689008713\n",
            "Epoch 1500 | Train Loss 0.06635680049657822\n",
            "Epoch 1600 | Train Loss 0.07224666327238083\n",
            "Epoch 1700 | Train Loss 0.04884345829486847\n",
            "Epoch 1800 | Train Loss 0.05118061229586601\n",
            "Epoch 1900 | Train Loss 0.07097186893224716\n"
          ]
        }
      ],
      "source": [
        "def train(data):\n",
        "    # Enumerate over the data\n",
        "    for batch in loader:\n",
        "      # Use GPU\n",
        "      batch.to(device)  \n",
        "      # Reset gradients\n",
        "      optimizer.zero_grad() \n",
        "    \n",
        "      # Passing the node features and the connection info\n",
        "      pred, embedding = model(batch.x.float(), batch.edge_index, batch.batch) \n",
        "      # Calculating the loss and gradients\n",
        "      y = torch.where(torch.isnan(batch.y), torch.zeros_like(batch.y), batch.y)\n",
        "      loss = loss_fn(pred, y)  \n",
        "      if not torch.isnan(loss):   \n",
        "        loss.backward()  \n",
        "        # Update using the gradients\n",
        "        optimizer.step()   \n",
        "\n",
        "    return loss, embedding\n",
        "\n",
        "print(\"Starting training...\")\n",
        "losses = []\n",
        "for epoch in range(2000):\n",
        "    loss, h = train(data)\n",
        "    losses.append(loss)\n",
        "    if epoch % 100 == 0:\n",
        "      print(f\"Epoch {epoch} | Train Loss {loss}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sYOm7p7WMlQc",
        "outputId": "755103e7-d2f6-4565-c3a4-61557eed51c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training...\n",
            "Epoch 0 | Test Loss 0.05326080694794655\n",
            "Epoch 100 | Test Loss 0.06610426306724548\n",
            "Epoch 200 | Test Loss 0.06576190143823624\n",
            "Epoch 300 | Test Loss 0.08225607872009277\n",
            "Epoch 400 | Test Loss 0.07145252823829651\n",
            "Epoch 500 | Test Loss 0.03840970620512962\n",
            "Epoch 600 | Test Loss 0.06023532152175903\n",
            "Epoch 700 | Test Loss 0.05051378533244133\n",
            "Epoch 800 | Test Loss 0.05139686167240143\n",
            "Epoch 900 | Test Loss 0.043788693845272064\n",
            "Epoch 1000 | Test Loss 0.07609823346138\n",
            "Epoch 1100 | Test Loss 0.06321408599615097\n",
            "Epoch 1200 | Test Loss 0.044042836874723434\n",
            "Epoch 1300 | Test Loss 0.047321200370788574\n",
            "Epoch 1400 | Test Loss 0.06436879932880402\n",
            "Epoch 1500 | Test Loss 0.05310908332467079\n",
            "Epoch 1600 | Test Loss 0.05180537328124046\n",
            "Epoch 1700 | Test Loss 0.04926084727048874\n",
            "Epoch 1800 | Test Loss 0.05187756195664406\n",
            "Epoch 1900 | Test Loss 0.04260827600955963\n"
          ]
        }
      ],
      "source": [
        "def test(data):\n",
        "    # Enumerate over the data\n",
        "    for batch in test_loader:\n",
        "      # Use GPU\n",
        "      batch.to(device)  \n",
        "      # Reset gradients\n",
        "      optimizer.zero_grad() \n",
        "      # Passing the node features and the connection info\n",
        "      pred, embedding = model(batch.x.float(), batch.edge_index, batch.batch) \n",
        "      # Calculating the loss and gradients\n",
        "      y = torch.where(torch.isnan(batch.y), torch.zeros_like(batch.y), batch.y)\n",
        "      loss = loss_fn(pred, y)  \n",
        "      if not torch.isnan(loss):   \n",
        "        loss.backward()  \n",
        "        # Update using the gradients\n",
        "        optimizer.step()   \n",
        "    return loss, embedding\n",
        "\n",
        "print(\"Starting testing...\")\n",
        "losses_test = []\n",
        "for epoch in range(2000):\n",
        "    loss, h = test(data)\n",
        "    losses_test.append(loss)\n",
        "    if epoch % 100 == 0:\n",
        "      print(f\"Epoch {epoch} | Test Loss {loss}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchmetrics import AUROC\n",
        "from torchmetrics import Accuracy\n",
        "\n",
        "\n",
        "def evaluate_train():\n",
        "  for batch in loader:\n",
        "    batch.to(device)\n",
        "    pred, embedding = model(batch.x.float(), batch.edge_index, batch.batch) \n",
        "    y = torch.where(torch.isnan(batch.y), torch.zeros_like(batch.y), batch.y).long()\n",
        "\n",
        "  auroc = AUROC(num_classes=12)\n",
        "  acc = Accuracy(num_classes=12)\n",
        "  return auroc(pred,y).item(), acc(pred,y).item()\n",
        "\n",
        "auroc_t, acc_t = evaluate_train()\n",
        "\n",
        "print(f\"Training ROC-AUC: {auroc_t}, Training accuracy: {acc_t}\")\n",
        "\n",
        "\n",
        "def evaluate_test():\n",
        "  for batch in test_loader:\n",
        "    batch.to(device)\n",
        "    pred, embedding = model(batch.x.float(), batch.edge_index, batch.batch) \n",
        "    y = torch.where(torch.isnan(batch.y), torch.zeros_like(batch.y), batch.y).long()\n",
        "\n",
        "  auroc = AUROC(num_classes=12)\n",
        "  acc = Accuracy(num_classes=12)\n",
        "  return auroc(pred,y).item(), acc(pred,y).item()\n",
        "\n",
        "auroc, acc = evaluate_test()\n",
        "\n",
        "print(f\"Test ROC-AUC: {auroc}, Test accuracy: {acc}\")\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lZT8sfvwAhcv",
        "outputId": "007f2550-2e7d-403b-8e32-7f4e3dacd8f1"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training ROC-AUC: 0.530190646648407, Training accuracy: 0.9244791865348816\n",
            "Test ROC-AUC: 0.3950921297073364, Test accuracy: 0.9301075339317322\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "test_batch = next(iter(test_loader))\n",
        "with torch.no_grad():\n",
        "    test_batch.to(device)\n",
        "    pred, embed = model(test_batch.x.float(), test_batch.edge_index, test_batch.batch) \n",
        "    df = pd.DataFrame()\n",
        "    y = torch.where(torch.isnan(test_batch.y), torch.zeros_like(test_batch.y), test_batch.y)\n",
        "    df[\"y_real\"] = test_batch.y.tolist()\n",
        "    df[\"y_pred\"] = pred.tolist()\n",
        "df[\"y_real\"] = df[\"y_real\"].apply(lambda row: row[0])\n",
        "df[\"y_pred\"] = df[\"y_pred\"].apply(lambda row: row[0])\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "IwTsMg86s1X9",
        "outputId": "f46b2ddd-6a8b-4b36-ae6f-3088585a590a"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    y_real    y_pred\n",
              "0      1.0  0.061936\n",
              "1      0.0  0.031290\n",
              "2      0.0  0.041060\n",
              "3      0.0  0.046457\n",
              "4      0.0  0.025290\n",
              "..     ...       ...\n",
              "59     0.0  0.051734\n",
              "60     0.0  0.062329\n",
              "61     0.0  0.003760\n",
              "62     0.0  0.054057\n",
              "63     0.0  0.023318\n",
              "\n",
              "[64 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ea4d7b91-79ff-49d5-9f1e-5250c11f8394\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>y_real</th>\n",
              "      <th>y_pred</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.061936</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.031290</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.041060</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.046457</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.025290</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.051734</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.062329</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.003760</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.054057</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.023318</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>64 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ea4d7b91-79ff-49d5-9f1e-5250c11f8394')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ea4d7b91-79ff-49d5-9f1e-5250c11f8394 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ea4d7b91-79ff-49d5-9f1e-5250c11f8394');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "plt = sns.scatterplot(data=df, x=\"y_real\", y=\"y_pred\")\n",
        "plt.set(xlim=(-0.5, 1.5))\n",
        "plt.set(ylim=(-0.05, 0.1))\n",
        "plt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        },
        "id": "CS9K8eiRtSsk",
        "outputId": "73b50def-2c4b-4c18-d198-525627936527"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f80a2f7f950>"
            ]
          },
          "metadata": {},
          "execution_count": 101
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
